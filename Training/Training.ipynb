{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a030e8d7-097b-4ad3-b20d-f70752828773",
   "metadata": {},
   "source": [
    "# Galaxy Image Generation with Diffusion Models\n",
    "\n",
    "Welcome to this tutorial on generating realistic galaxy images using diffusion models! This project demonstrates how to train a sophisticated AI model that can create synthetic galaxy images that are virtually indistinguishable from real astronomical observations.\n",
    "\n",
    "Diffusion models represent a cutting-edge approach to image generation. Unlike other generative models (like GANs), diffusion models work by gradually adding noise to images and then learning to reverse this process. This approach often leads to more stable training and higher quality outputs, which is crucial when dealing with complex astronomical data.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before we dive into the model implementation, we need to set up our development environment. This section handles all necessary imports and configurations to ensure smooth execution of our training pipeline.\n",
    "\n",
    "Key components we're setting up:\n",
    "1. **Deep Learning Framework**: We use PyTorch as our primary framework due to its flexibility and robust GPU support\n",
    "2. **Data Processing**: NumPy and custom data handlers for efficient galaxy image processing\n",
    "3. **Progress Tracking**: \n",
    "   - TensorBoard for real-time visualization\n",
    "   - Custom logging for detailed progress tracking\n",
    "   - TQDM for progress bars\n",
    "4. **GPU Acceleration**: CUDA configuration for faster training\n",
    "5. **Warning Management**: Suppression of non-critical warnings to keep our output clean\n",
    "\n",
    "The code below configures all these components and verifies our setup is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eeadc66-edac-4a07-a121-40fb7b3c602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow logging\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0 = all logs, 1 = INFO, 2 = WARNING, 3 = ERROR\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random \n",
    "import threading\n",
    "import copy \n",
    "from copy import deepcopy\n",
    "from data_manage import HDF5ImageGenerator  \n",
    "from modules import EMA, UNet_conditional_conv   \n",
    "from utils import setup_logging, save_images   \n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision.utils import make_grid\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torchvision.transforms.functional as F\n",
    "import subprocess\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "import h5py\n",
    "import glob\n",
    "  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "warnings.filterwarnings('ignore', message='You are using `torch.load` with `weights_only=False`')\n",
    "# Suppress the learning rate scheduler warning\n",
    "warnings.filterwarnings('ignore', message='The verbose parameter is deprecated.*')\n",
    "\n",
    "# Suppress the tensorboard log directory warning\n",
    "warnings.filterwarnings('ignore', message='.*logs will be written to.*')\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcd91b-bd30-4ae6-9762-a44f96f2b3b1",
   "metadata": {},
   "source": [
    "## Logging Configuration\n",
    "\n",
    "This section sets up a dual-level logging system for training monitoring and debugging. The code creates three main components:\n",
    "\n",
    "### 1. Directory Setup\n",
    "- Creates directories for:\n",
    "  - Model checkpoints: './Model_Checkpoints'\n",
    "  - TensorBoard logs: './tens_logs'\n",
    "  - Training logs: './Logs'\n",
    "\n",
    "### 2. Logger Configuration\n",
    "The main logger setup includes:\n",
    "- Debug level for file logging\n",
    "- Info level for console output\n",
    "- Custom timestamp formatting: \"HH:MM:SS - LEVEL: MESSAGE\"\n",
    "- Avoids duplicate logging by clearing existing handlers\n",
    "- Prevents log propagation to parent loggers\n",
    "\n",
    "### 3. Log Handlers\n",
    "Two handlers are configured:\n",
    "- **File Handler**\n",
    "  - Saves to 'training.log'\n",
    "  - Captures DEBUG level and above\n",
    "  - Maintains permanent training record\n",
    "\n",
    "- **Console Handler**\n",
    "  - Displays in terminal\n",
    "  - Shows INFO level and above\n",
    "  - Provides real-time feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520d8c19-f097-4a48-9fe7-38ab6f6f4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "checkpoint_dir = './Model_Checkpoints'\n",
    "tensorboard_log_dir = \"./tens_logs\"\n",
    "logging_dir = './Logs'\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "os.makedirs(logging_dir, exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "log_file = os.path.join(logging_dir, 'training.log')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Remove existing handlers to avoid duplication\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# Prevent log propagation\n",
    "logger.propagate = False\n",
    "\n",
    "# Create and configure handlers\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create and set formatter\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s - %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%I:%M:%S\"\n",
    ")\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Add handlers to logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "logger.info(\"Logging system initialized\")\n",
    "logger.debug(\"Debug logging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c608a6-2cd4-4eec-a4d2-7f7fc70a8a16",
   "metadata": {},
   "source": [
    "## Reproducibility Configuration\n",
    "\n",
    "This section sets up consistent random number generation across all components to ensure reproducible results. We have two main functions:\n",
    "\n",
    "### 1. Global Seed Setting\n",
    "The `set_random_seed` function sets seeds for:\n",
    "- Python's random module\n",
    "- NumPy random generator\n",
    "- PyTorch (CPU operations)\n",
    "- CUDA (if GPU available)\n",
    "- CuDNN behavior settings:\n",
    "  - Deterministic mode enabled\n",
    "  - Benchmark mode disabled\n",
    "\n",
    "### 2. Worker Seed Initialization\n",
    "The `worker_init_fn` function:\n",
    "- Used by DataLoader workers\n",
    "- Creates unique seeds for each worker\n",
    "- Ensures consistent data loading across runs\n",
    "\n",
    "We use seed=42 as our default random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f659b18d-bb9f-465f-b8bc-385d0ef8d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    # Set seed for Python's built-in random module\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Set seed for NumPy\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Set seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # If you are using CUDA\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    \n",
    "    # For deterministic behavior (may be slower on some systems)\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacb1313-2272-46ae-a401-d3707840a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42   \n",
    "set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a92dc4-e36f-4f75-9360-5c648940a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Initialize each worker with a different random seed based on the worker id.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32 + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62176bd-491e-457c-b9a1-0e24be765ae8",
   "metadata": {},
   "source": [
    "## Data Processing and Normalization\n",
    "\n",
    "This section handles the normalization of our 5-band (g,r,i,z,y) galaxy images and implements validation data selection. We have three main functions:\n",
    "\n",
    "### 1. Image Normalization\n",
    "The `normalize_images` function:\n",
    "- Takes raw galaxy images in all 5 bands\n",
    "- Normalizes them to [-1, 1] range using pre-computed statistics:\n",
    "  - Minimum value: -25241.32\n",
    "  - Maximum value: 3647.6323\n",
    "- Includes checks for NaN values\n",
    "- Clips outliers to ensure valid range\n",
    "\n",
    "### 2. Image Denormalization\n",
    "The `denormalize_images` function:\n",
    "- Converts normalized images back to original scale\n",
    "- Used mainly for visualization and saving results\n",
    "- Reverses the normalization process exactly\n",
    "\n",
    "### 3. Validation Batch Selection\n",
    "The `get_random_val_batch` function:\n",
    "- Randomly samples a batch of images from validation set\n",
    "- Checks for empty datasets and NaN values\n",
    "- Returns both images and their corresponding labels\n",
    "- Handles errors with appropriate logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdac1240-d9fc-4f42-b772-567b970e35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    \"\"\"\n",
    "    Normalize astronomical images to [-1, 1] range using pre-computed dataset statistics.\n",
    "    \n",
    "    Args:\n",
    "        images (torch.Tensor): Raw input images\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Normalized images in [-1, 1] range\n",
    "    \"\"\"\n",
    "    min_val, max_val = -25241.32, 3647.6323  # Pre-computed statistics\n",
    "    \n",
    "    # Input validation\n",
    "    if torch.isnan(images).any():\n",
    "        raise ValueError(\"Input images contain NaN values\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Scale to [0, 1]\n",
    "        images = (images - min_val) / (max_val - min_val)\n",
    "        \n",
    "        # Clip any potential outliers\n",
    "        images = torch.clamp(images, 0, 1)\n",
    "        \n",
    "        # Step 2: Scale to [-1, 1]\n",
    "        images = images * 2 - 1\n",
    "        \n",
    "        return images\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Normalization failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def denormalize_images(images):\n",
    "    \"\"\"\n",
    "    Convert normalized images back to original astronomical scale.\n",
    "    \"\"\"\n",
    "    min_val, max_val = -25241.32, 3647.6323\n",
    "    \n",
    "    try:\n",
    "        # Reverse [-1, 1] scaling\n",
    "        images = (images + 1) / 2\n",
    "        \n",
    "        # Reverse [0, 1] scaling\n",
    "        images = images * (max_val - min_val) + min_val\n",
    "        \n",
    "        return images\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Denormalization failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def get_random_val_batch(val_loader):\n",
    "    \"\"\"\n",
    "    Get a random batch of validation images for visualization.\n",
    "    \"\"\"\n",
    "    val_dataset = val_loader.dataset\n",
    "    batch_size = val_loader.batch_size\n",
    "    \n",
    "    try:\n",
    "        if len(val_dataset) == 0:\n",
    "            logger.warning(\"Empty validation dataset\")\n",
    "            return None, None\n",
    "            \n",
    "        # Random sampling with validation\n",
    "        indices = random.sample(range(len(val_dataset)), batch_size)\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        for idx in indices:\n",
    "            img, label = val_dataset[idx]\n",
    "            \n",
    "            # Validate image and label\n",
    "            if torch.isnan(img).any():\n",
    "                logger.warning(f\"NaN values found in image at index {idx}\")\n",
    "                continue\n",
    "                \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            \n",
    "        # Stack valid samples\n",
    "        if not images:\n",
    "            return None, None\n",
    "            \n",
    "        images = torch.stack(images)\n",
    "        labels = torch.stack(labels)\n",
    "        \n",
    "        return images, labels\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in random batch selection: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ad2f5-76e1-4b89-9ad9-16392d385d54",
   "metadata": {},
   "source": [
    "## Checkpoint Management\n",
    "\n",
    "This section handles saving and loading model checkpoints, ensuring we can resume training and maintain best models. We have two main functions:\n",
    "\n",
    "### 1. Saving Checkpoints\n",
    "The `save_checkpoint` function saves:\n",
    "- Model state and configuration\n",
    "- Training progress:\n",
    "  - Current epoch\n",
    "  - Loss values\n",
    "  - Best validation loss\n",
    "  - Learning rate\n",
    "  - Batch size\n",
    "- Random states:\n",
    "  - Python\n",
    "  - NumPy\n",
    "  - PyTorch\n",
    "  - CUDA (if available)\n",
    "- Diffusion model parameters:\n",
    "  - Noise steps\n",
    "  - Beta start/end values\n",
    "\n",
    "### 2. Loading Checkpoints\n",
    "The `load_checkpoint` function:\n",
    "- Finds and loads the latest checkpoint\n",
    "- Restores:\n",
    "  - Model state\n",
    "  - Optimizer state\n",
    "  - EMA state (if available)\n",
    "  - Training parameters\n",
    "- Ensures all tensors are on correct device\n",
    "- Returns the last completed epoch number\n",
    "\n",
    "Both functions include error handling and logging for tracking the checkpoint process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee099dd1-3207-46c9-bd36-3b309d07b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, ema, optimizer, epoch, checkpoint_dir, args, average_loss, diffusion, best_val_loss):   \n",
    "    \"\"\"\n",
    "    Enhanced checkpoint saving with better error handling and metadata.\n",
    "\n",
    "    This function saves the current state of the training process, including the model, optimizer, and other relevant information, to a checkpoint file. The checkpoint can be used to resume training from the saved state later.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be saved.\n",
    "        ema (ExponentialMovingAverage): The Exponential Moving Average (EMA) model, if being used.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to be saved.\n",
    "        epoch (int): The current epoch of training.\n",
    "        checkpoint_dir (str): The directory where the checkpoint file will be saved.\n",
    "        args (argparse.Namespace): The command-line arguments used for training.\n",
    "        average_loss (float): The average training loss for the current epoch.\n",
    "        diffusion (Diffusion): The diffusion model object.\n",
    "        best_val_loss (float): The best validation loss achieved so far.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Construct the checkpoint file path\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch:04d}.pth')\n",
    "        \n",
    "        # Convert Python's random state tuple to a list of numbers that can be properly serialized\n",
    "        python_state = random.getstate()\n",
    "        python_state_list = [python_state[0], list(python_state[1]), python_state[2]]\n",
    "        \n",
    "        # Prepare the checkpoint state dictionary\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'ema_state_dict': ema.state_dict() if ema else None,\n",
    "            'loss': average_loss,\n",
    "            'best_val_loss': best_val_loss,   \n",
    "            'learning_rate': args.lr,\n",
    "            'batch_size': args.batch_size,\n",
    "            'diffusion_params': {\n",
    "                'noise_steps': diffusion.noise_steps,\n",
    "                'beta_start': diffusion.beta_start,\n",
    "                'beta_end': diffusion.beta_end\n",
    "            },\n",
    "            'args': vars(args),\n",
    "            'random_state': {\n",
    "                'python': python_state_list,\n",
    "                'numpy': np.random.get_state(),\n",
    "                'torch': torch.get_rng_state(),\n",
    "                'torch_cuda': torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # Save the checkpoint\n",
    "        torch.save(state, checkpoint_path)\n",
    "        logger.debug(f\"Checkpoint saved at epoch {epoch + 1} to {checkpoint_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save checkpoint at epoch {epoch + 1}: {e}\")\n",
    "        raise\n",
    "\n",
    "def load_checkpoint(model, ema, optimizer, checkpoint_dir, args, diffusion, device, start_epoch=None):\n",
    "    \"\"\"\n",
    "    Enhanced checkpoint loading with better error handling and state restoration.\n",
    "\n",
    "    This function attempts to load the latest checkpoint from the specified checkpoint directory. If a checkpoint is found, it restores the model, optimizer, and other relevant state, allowing the training process to be resumed from the saved state.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be loaded.\n",
    "        ema (ExponentialMovingAverage): The Exponential Moving Average (EMA) model, if being used.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to be loaded.\n",
    "        checkpoint_dir (str): The directory containing the checkpoint files.\n",
    "        args (argparse.Namespace): The command-line arguments.\n",
    "        diffusion (Diffusion): The diffusion model object.\n",
    "        device (torch.device): The device to load the model onto.\n",
    "        start_epoch (int, optional): The epoch to start from (if not provided, the latest checkpoint is used).\n",
    "\n",
    "    Returns:\n",
    "        int: The epoch from which to start training.\n",
    "    \"\"\"\n",
    "    epoch = 0\n",
    "\n",
    "    try:\n",
    "        if start_epoch is None:\n",
    "            # Find the latest checkpoint\n",
    "            checkpoints = sorted([\n",
    "                f for f in os.listdir(checkpoint_dir)\n",
    "                if f.startswith('checkpoint_epoch_') and f.endswith('.pth')\n",
    "            ])\n",
    "\n",
    "            if checkpoints:\n",
    "                # Load the latest checkpoint\n",
    "                latest_checkpoint = os.path.join(checkpoint_dir, checkpoints[-1])\n",
    "                checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
    "\n",
    "                # Load model state and move to device\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                model.to(device)\n",
    "                logger.debug(f\"Model loaded and moved to device {device}\")\n",
    "\n",
    "                # Load optimizer state and ensure device consistency\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                for state in optimizer.state.values():\n",
    "                    for k, v in state.items():\n",
    "                        if isinstance(v, torch.Tensor):\n",
    "                            state[k] = v.to(device)\n",
    "\n",
    "                # Load EMA state and ensure device consistency\n",
    "                if 'ema_state_dict' in checkpoint and ema is not None:\n",
    "                    ema.load_state_dict(checkpoint['ema_state_dict'])\n",
    "                    for k, v in ema.shadow.items():\n",
    "                        ema.shadow[k] = v.to(device)\n",
    "                    logger.debug(\"EMA state restored from checkpoint\")\n",
    "\n",
    "                # Load additional parameters\n",
    "                epoch = checkpoint.get('epoch', 0)\n",
    "                args.lr = checkpoint.get('learning_rate', args.lr)\n",
    "                args.batch_size = checkpoint.get('batch_size', args.batch_size)\n",
    "\n",
    "                # Load diffusion parameters if available\n",
    "                diffusion_params = checkpoint.get('diffusion_params', None)\n",
    "                if diffusion_params:\n",
    "                    diffusion.noise_steps = diffusion_params.get('noise_steps', diffusion.noise_steps)\n",
    "                    diffusion.beta_start = diffusion_params.get('beta_start', diffusion.beta_start)\n",
    "                    diffusion.beta_end = diffusion_params.get('beta_end', diffusion.beta_end)\n",
    "\n",
    "                # Return the best validation loss if it exists in the checkpoint\n",
    "                best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "                logger.info(f\"Loaded checkpoint from epoch {epoch} with best val loss: {best_val_loss:.4f}\")\n",
    "\n",
    "                logger.info(f\"Successfully loaded checkpoint from epoch {epoch}\")\n",
    "            else:\n",
    "                logger.info(\"No checkpoints found. Starting from scratch.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load checkpoint: {e}\")\n",
    "        raise\n",
    "\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517af631-220d-447b-b840-711602794a96",
   "metadata": {},
   "source": [
    "## Diffusion Model\n",
    "\n",
    "Our `Diffusion` class implements the core diffusion process with five main methods:\n",
    "\n",
    "### 1. Initialization\n",
    "Sets up the diffusion parameters:\n",
    "- 1000 noise steps\n",
    "- Beta schedule from 1e-4 to 0.02\n",
    "- Image size (default 64x64)\n",
    "- Computes alpha values and cumulative products\n",
    "- Configures device (CPU/GPU)\n",
    "\n",
    "### 2. Noise Schedule\n",
    "`prepare_noise_schedule`:\n",
    "- Creates linear noise schedule\n",
    "- Returns evenly spaced values from beta_start to beta_end\n",
    "\n",
    "### 3. Image Noising\n",
    "`noise_images`:\n",
    "- Adds noise to input images\n",
    "- Takes timestep t as parameter\n",
    "- Returns both noised image and noise added\n",
    "\n",
    "### 4. Timestep Sampling\n",
    "`sample_timesteps`:\n",
    "- Randomly samples timesteps for training\n",
    "- Returns integers from 1 to noise_steps\n",
    "\n",
    "### 5. Image Generation\n",
    "`sample`:\n",
    "- Generates n new images from noise\n",
    "- Uses provided model for denoising\n",
    "- Conditions on input labels\n",
    "- Gradually denoises through all timesteps\n",
    "- Returns generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8633abae-53ab-43a4-bb4c-51633ce1e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "   def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=64, device=\"cuda\"):\n",
    "       \"\"\"\n",
    "       Initialize diffusion process parameters.\n",
    "       \n",
    "       Args:\n",
    "           noise_steps: Number of steps to add noise (default 1000)\n",
    "           beta_start: Initial noise level (default 1e-4)\n",
    "           beta_end: Final noise level (default 0.02)\n",
    "           img_size: Size of images (default 64x64)\n",
    "           device: Device to run on (default \"cuda\")\n",
    "       \"\"\"\n",
    "       # Basic parameters\n",
    "       self.noise_steps = noise_steps\n",
    "       self.beta_start = beta_start\n",
    "       self.beta_end = beta_end\n",
    "       \n",
    "       # Create noise schedule\n",
    "       self.beta = self.prepare_noise_schedule().to(device)\n",
    "       # Calculate alpha values (1 - beta)\n",
    "       self.alpha = 1. - self.beta\n",
    "       # Calculate cumulative products of alpha\n",
    "       self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "       \n",
    "       self.img_size = img_size\n",
    "       self.device = device\n",
    "\n",
    "   def prepare_noise_schedule(self):\n",
    "       \"\"\"Create linear noise schedule from beta_start to beta_end\"\"\"\n",
    "       return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "   def noise_images(self, x, t):\n",
    "       \"\"\"\n",
    "       Add noise to images at timestep t\n",
    "       \n",
    "       Args:\n",
    "           x: Input images\n",
    "           t: Timesteps to add noise at\n",
    "       Returns:\n",
    "           Noised images and the noise that was added\n",
    "       \"\"\"\n",
    "       # Get alpha values for timesteps\n",
    "       sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "       sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "       # Generate random noise\n",
    "       epsilon = torch.randn_like(x)\n",
    "       # Return noised image and the noise\n",
    "       return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * epsilon, epsilon\n",
    "\n",
    "   def sample_timesteps(self, n):\n",
    "       \"\"\"Generate n random timesteps between 1 and noise_steps\"\"\"\n",
    "       return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "   def sample(self, model, n, labels):\n",
    "       \"\"\"\n",
    "       Generate n new images using the diffusion model\n",
    "       \n",
    "       Args:\n",
    "           model: UNet model for noise prediction\n",
    "           n: Number of images to generate\n",
    "           labels: Redshift labels to condition on\n",
    "       \"\"\"\n",
    "       logging.info(f\"Sampling {n} new images....\")\n",
    "       model.eval()\n",
    "       with torch.no_grad():\n",
    "           # Start from random noise\n",
    "           x = torch.randn((n, 5, self.img_size, self.img_size)).to(self.device)\n",
    "           \n",
    "           # Gradually denoise the images\n",
    "           for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "               t = (torch.ones(n) * i).long().to(self.device)\n",
    "               # Predict noise at current step\n",
    "               predicted_noise = model(x, t, labels)\n",
    "               # Get alpha values for current step\n",
    "               alpha = self.alpha[t][:, None, None, None]\n",
    "               alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "               beta = self.beta[t][:, None, None, None]\n",
    "               \n",
    "               # Add random noise except at final step\n",
    "               if i > 1:\n",
    "                   noise = torch.randn_like(x)\n",
    "               else:\n",
    "                   noise = torch.zeros_like(x)\n",
    "                   \n",
    "               # Denoising step\n",
    "               x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "       \n",
    "       model.train()\n",
    "       return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1eac7c-30d4-497a-9ee5-0c626e8d88e3",
   "metadata": {},
   "source": [
    "## Best Model Saving\n",
    "\n",
    "The `save_best_model` function saves the model state when we achieve a new best validation loss. \n",
    "\n",
    "### Saved State Components\n",
    "The function saves:\n",
    "- Training state:\n",
    "  - Current epoch\n",
    "  - Loss values\n",
    "  - Validation loss\n",
    "  - Learning rate\n",
    "  - Batch size\n",
    "- Model states:\n",
    "  - Main model\n",
    "  - Optimizer\n",
    "  - EMA (if present)\n",
    "- Configuration:\n",
    "  - Diffusion parameters\n",
    "  - Command line arguments\n",
    "- Random states:\n",
    "  - Python\n",
    "  - NumPy\n",
    "  - PyTorch CPU/CUDA\n",
    "\n",
    "Includes error handling and logging for tracking save operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84fa7ffe-c23b-4e8f-9e38-0beef2c22461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(model, ema, optimizer, epoch, val_loss, best_model_path, args, average_loss, diffusion):\n",
    "   \"\"\"\n",
    "   Saves the best model based on validation loss with enhanced error handling.\n",
    "   \n",
    "   Args:\n",
    "       model: The UNet model to save\n",
    "       ema: Exponential Moving Average model\n",
    "       optimizer: The optimizer state\n",
    "       epoch: Current epoch number\n",
    "       val_loss: Current validation loss\n",
    "       best_model_path: Where to save the model\n",
    "       args: Training arguments and config\n",
    "       average_loss: Average training loss\n",
    "       diffusion: Diffusion model parameters\n",
    "   \"\"\"\n",
    "   try:\n",
    "       # Create dictionary containing all states we want to save\n",
    "       state = {\n",
    "           # Training progress\n",
    "           'epoch': epoch,                                    # Current epoch\n",
    "           'loss': average_loss,                             # Training loss\n",
    "           'val_loss': val_loss,                             # Current validation loss\n",
    "           'best_val_loss': val_loss,                        # Best validation loss (same as val_loss for best model)\n",
    "           \n",
    "           # Model states\n",
    "           'model_state_dict': model.state_dict(),           # Main model weights\n",
    "           'optimizer_state_dict': optimizer.state_dict(),    # Optimizer state\n",
    "           'ema_state_dict': ema.state_dict() if ema else None,  # EMA model weights if exists\n",
    "           \n",
    "           # Training configuration\n",
    "           'learning_rate': args.lr,                         # Current learning rate\n",
    "           'batch_size': args.batch_size,                    # Batch size used\n",
    "           \n",
    "           # Diffusion model parameters\n",
    "           'diffusion_params': {\n",
    "               'noise_steps': diffusion.noise_steps,         # Number of noise steps\n",
    "               'beta_start': diffusion.beta_start,           # Starting noise value\n",
    "               'beta_end': diffusion.beta_end               # Ending noise value\n",
    "           },\n",
    "           \n",
    "           # Full configuration\n",
    "           'args': vars(args),                              # All training arguments\n",
    "           \n",
    "           # Random states for reproducibility\n",
    "           'random_state': {\n",
    "               'python': random.getstate(),                  # Python random state\n",
    "               'numpy': np.random.get_state(),               # NumPy random state\n",
    "               'torch': torch.get_rng_state(),               # PyTorch CPU random state\n",
    "               'torch_cuda': torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,  # GPU random state\n",
    "           },\n",
    "       }\n",
    "       \n",
    "       # Save the state dictionary\n",
    "       torch.save(state, best_model_path)\n",
    "       logger.debug(f\"Best model saved at epoch {epoch + 1} with validation loss {val_loss:.4f}\")\n",
    "       \n",
    "   except Exception as e:\n",
    "       # Log error if saving fails\n",
    "       logger.error(f\"Failed to save best model: {e}\")\n",
    "       raise  # Re-raise the exception for the caller to handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c64df6-39be-40a2-b433-765d56458cbc",
   "metadata": {},
   "source": [
    "## Training Arguments\n",
    "\n",
    "The `Args` class defines all training configurations in one place. While these parameters can be modified, we recommend keeping the default values as they've been optimized for galaxy generation, except for the number of epochs which you can adjust based on your training needs.\n",
    "\n",
    "### Training Parameters\n",
    "- Batch size: 128 (recommended default)\n",
    "- Number of epochs: 600 (adjustable based on your needs)\n",
    "- Learning rate: 5e-5 (recommended default)\n",
    "- Image size: 64x64 (recommended default)\n",
    "- Random seed: 42 (recommended default)\n",
    "\n",
    "### Data Paths\n",
    "- Training: 5x64x64_training_with_morphology.hdf5\n",
    "- Validation: 5x64x64_validation_with_morphology.hdf5\n",
    "- Testing: 5x64x64_testing_with_morphology.hdf5\n",
    "\n",
    "### Checkpoint Control\n",
    "Two parameters control how training resumes:\n",
    "- `resume`: If True, loads from a checkpoint. If False, starts fresh training\n",
    "- `start_epoch`: \n",
    "  - None: Automatically finds and loads the latest checkpoint\n",
    "  - Integer value: Loads a specific epoch's checkpoint (e.g., 100 for epoch 100)\n",
    "\n",
    "### Runtime Settings\n",
    "- Device: CUDA if available, CPU otherwise\n",
    "- Run name: \"DDPM_conditional_continuous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4220785a-ced8-4ce6-afbb-8a4f1ec25492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Args class\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.resume = True  # Set to True to resume training from the latest checkpoint\n",
    "        self.run_name = \"DDPM_conditional_continuous\"\n",
    "        self.batch_size = 128\n",
    "        self.epochs = 600\n",
    "        self.image_size = 64\n",
    "        self.train_path = r'/shared/astrodata/5x64x64_training_with_morphology.hdf5'\n",
    "        self.validation_path = r'/shared/astrodata/5x64x64_validation_with_morphology.hdf5'\n",
    "        self.test_path = r'/shared/astrodata/5x64x64_testing_with_morphology.hdf5'\n",
    "        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        self.lr = 5e-5\n",
    "        self.start_epoch = None  # Set this to specify a specific checkpoint epoch, or None for the latest\n",
    "        self.seed = 42   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca676cfc-dd49-4717-98a4-b9947047f7a3",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "\n",
    "The `validate` function evaluates model performance on the validation dataset. It processes batches of images with the following steps:\n",
    "\n",
    "### Process Steps\n",
    "1. Sets model to evaluation mode\n",
    "2. Disables gradient calculations for efficiency\n",
    "3. For each batch:\n",
    "   - Moves images and labels to correct device\n",
    "   - Normalizes images to [-1, 1] range\n",
    "   - Adds noise using diffusion process\n",
    "   - Predicts noise using model\n",
    "   - Calculates loss\n",
    "4. Returns average loss across all batches\n",
    "\n",
    "### Label Handling\n",
    "Ensures proper label dimensions:\n",
    "- 0D labels → 2D tensors\n",
    "- 1D labels → 2D tensors\n",
    "\n",
    "The function operates without gradients to save memory during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcf3e7da-db2e-41c3-9643-eeca29ca4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, diffusion, device, loss_fn):\n",
    "   \"\"\"\n",
    "   Validate the model and return the average validation loss.\n",
    "   \n",
    "   Args:\n",
    "       model: The UNet model being trained\n",
    "       val_loader: DataLoader for validation data\n",
    "       diffusion: Diffusion process instance\n",
    "       device: Device (CPU/GPU) to run validation on\n",
    "       loss_fn: Loss function (Smooth L1/Huber loss)\n",
    "   Returns:\n",
    "       avg_loss: Average loss across all validation batches\n",
    "   \"\"\"\n",
    "   # Set model to evaluation mode (disables dropout, etc.)\n",
    "   model.eval()\n",
    "   total_loss = 0.0\n",
    "   batch_count = 0\n",
    "   \n",
    "   # Disable gradient computation for validation\n",
    "   with torch.no_grad():\n",
    "       for images, labels in val_loader:\n",
    "           # Move data to appropriate device\n",
    "           images = images.to(device)\n",
    "           labels = labels.float().to(device)\n",
    "           \n",
    "           # Ensure labels have correct shape (Batch x 1)\n",
    "           if labels.dim() == 0:  # Single value\n",
    "               labels = labels.unsqueeze(0).unsqueeze(1)\n",
    "           elif labels.dim() == 1:  # Batch of values\n",
    "               labels = labels.unsqueeze(1)\n",
    "           \n",
    "           # Preprocess images and add noise\n",
    "           images = normalize_images(images)  # Scale to [-1, 1]\n",
    "           t = diffusion.sample_timesteps(images.size(0)).to(device)  # Get random timesteps\n",
    "           x_t, noise = diffusion.noise_images(images, t)  # Add noise to images\n",
    "           \n",
    "           # Get model's noise prediction\n",
    "           predicted_noise = model(x_t, t, labels)\n",
    "           \n",
    "           # Calculate loss between real and predicted noise\n",
    "           loss = loss_fn(noise, predicted_noise)\n",
    "           total_loss += loss.item()\n",
    "           batch_count += 1\n",
    "           \n",
    "   # Calculate average loss across all batches\n",
    "   avg_loss = total_loss / batch_count\n",
    "   logger.debug(f\"Validation completed with average loss: {avg_loss:.4f}\")\n",
    "   \n",
    "   # Return model to training mode\n",
    "   model.train()\n",
    "   return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5f323-962c-4844-bf2a-fbbdf9522745",
   "metadata": {},
   "source": [
    "## Data Loading Setup\n",
    "\n",
    "This section configures and initializes our data loaders for both training and validation data.\n",
    "\n",
    "### Data Generator Settings\n",
    "Configures HDF5 data loading with:\n",
    "- Input: 'image' (5-band galaxy images)\n",
    "- Target: 'specz_redshift' (spectroscopic redshift)\n",
    "  - Range: 0 to 4\n",
    "  - Represents galaxy's distance/age\n",
    "  - Used as conditioning for generation\n",
    "  - Helps model learn redshift-dependent features\n",
    "- No scaling or augmentation applied\n",
    "- Smoothing factor: 0.1\n",
    "\n",
    "### DataLoader Configuration\n",
    "- Batch size: From Args class\n",
    "- Workers: 4 parallel loaders\n",
    "- Pin memory: Enabled for faster GPU transfer\n",
    "- Shuffle: \n",
    "  - Training: Enabled (prevents model from learning batch order)\n",
    "  - Validation: Disabled (keeps consistent ordering for progress tracking)\n",
    "\n",
    "The model learns to generate galaxies conditioned on redshift, meaning it can create images of galaxies as they would appear at different distances/ages in the universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76f6ef94-d57d-4fd1-a608-5fcdef8808a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arguments from Args class\n",
    "args = Args()\n",
    "\n",
    "# Data generator arguments for training data\n",
    "train_gen_args = {\n",
    "   'X_key': 'image',              # Key for accessing image data in HDF5\n",
    "   'y_key': 'specz_redshift',     # Key for accessing redshift labels\n",
    "   'scaler': False,               # Don't scale the input images\n",
    "   'labels_encoding': False,       # No encoding needed for continuous redshift values\n",
    "   'num_classes': None,           # Not using classification\n",
    "   'shuffle': True,               # Shuffle data during training\n",
    "   'y_scaler': False,             # Don't scale the redshift values\n",
    "   'y_range': (0, 4),            # Redshift range from 0 to 4\n",
    "   'augmenter': False,            # No data augmentation\n",
    "   'smooth_factor': 0.1,          # Small smoothing factor for labels\n",
    "}\n",
    "\n",
    "# Similar arguments for validation data, but with shuffle=False\n",
    "val_gen_args = {\n",
    "   'X_key': 'image',\n",
    "   'y_key': 'specz_redshift', \n",
    "   'scaler': False,\n",
    "   'labels_encoding': False,\n",
    "   'num_classes': None,\n",
    "   'shuffle': False,              # Don't shuffle validation data\n",
    "   'y_scaler': False,\n",
    "   'y_range': (0, 4),\n",
    "   'augmenter': False,\n",
    "   'smooth_factor': 0.1,\n",
    "}\n",
    "\n",
    "# Initialize HDF5 dataset for training\n",
    "train_dataset = HDF5ImageGenerator(\n",
    "   src=args.train_path,           # Path to training HDF5 file\n",
    "   mode='train',                  # Training mode\n",
    "   X_key='image',                 # Access images in HDF5\n",
    "   y_key='specz_redshift',        # Access redshifts in HDF5\n",
    "   scaler=False,                  # Raw image values\n",
    "   labels_encoding=False,         # Raw redshift values\n",
    "   num_classes=None,              # Not using classification\n",
    "   shuffle=False,                 # DataLoader will handle shuffling\n",
    "   y_scaler=False,               # Keep original redshift scale\n",
    "   y_range=(0, 4),               # Valid redshift range\n",
    "   augmenter=False,              # No augmentation\n",
    "   smooth_factor=0.1             # Small label smoothing\n",
    ")\n",
    "\n",
    "# Initialize HDF5 dataset for validation\n",
    "val_dataset = HDF5ImageGenerator(\n",
    "   src=args.validation_path,      # Path to validation HDF5 file\n",
    "   mode='test',                   # Test/validation mode\n",
    "   X_key='image',\n",
    "   y_key='specz_redshift',\n",
    "   scaler=False,\n",
    "   labels_encoding=False,\n",
    "   num_classes=None,\n",
    "   shuffle=False,\n",
    "   y_scaler=False,\n",
    "   y_range=(0, 4),\n",
    "   augmenter=False,\n",
    "   smooth_factor=0.1\n",
    ")\n",
    "\n",
    "# Create PyTorch DataLoader for efficient batching and parallel loading\n",
    "train_loader = DataLoader(\n",
    "   train_dataset,\n",
    "   batch_size=args.batch_size,    # Batch size from Args\n",
    "   shuffle=True,                  # Shuffle training data\n",
    "   num_workers=4,                 # Use 4 parallel processes\n",
    "   pin_memory=True               # Speed up GPU transfer\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_loader = DataLoader(\n",
    "   val_dataset,\n",
    "   batch_size=args.batch_size,\n",
    "   shuffle=False,                 # Don't shuffle validation data\n",
    "   num_workers=4,                 # Use 4 parallel processes\n",
    "   pin_memory=True               # Speed up GPU transfer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bd414-731d-48af-8e80-2464176e5194",
   "metadata": {},
   "source": [
    "## Data Inspection\n",
    "\n",
    "This section verifies our dataset is loaded correctly before training begins.\n",
    "\n",
    "The `inspect_labels` function provides comprehensive data verification:\n",
    "- Displays the first few galaxy images\n",
    "- Shows corresponding redshift values\n",
    "- Verifies data loading and normalization\n",
    "- Checks for NaN/Inf values\n",
    "- Optional: Shows histogram distribution of all redshifts\n",
    "\n",
    "Usage:\n",
    "```python\n",
    "# Default: view 3 samples\n",
    "inspect_labels(train_dataset, device)\n",
    "\n",
    "# Custom: view 5 samples and show redshift distribution\n",
    "inspect_labels(train_dataset, device, num_samples=5, plot_histogram=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f6cd7d-60c3-40a1-bd7c-d4ef718755bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_labels(dataset, device, num_samples=3, plot_histogram=False):\n",
    "    \"\"\"\n",
    "    Inspects labels in the dataset by displaying the first few images with their redshifts\n",
    "    and optionally plotting a histogram of all redshift labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Only print these three pieces of information\n",
    "        print(f\"Dataset type: {type(dataset)}\")\n",
    "        print(f\"Dataset length: {len(dataset)}\")\n",
    "        print(f\"Accessing indices: {list(range(num_samples))}\")\n",
    "        \n",
    "        # Get the samples silently\n",
    "        images_batch, labels_batch = zip(*[dataset[i] for i in range(num_samples)])\n",
    "        \n",
    "        # Process without printing\n",
    "        images_batch = [img.float() for img in images_batch]\n",
    "        labels_batch = [label.float() if isinstance(label, torch.Tensor) else torch.tensor(label, dtype=torch.float32) for label in labels_batch]\n",
    "\n",
    "        # Stack tensors and move to device\n",
    "        images = torch.stack(images_batch).to(device, non_blocking=True)\n",
    "        labels = torch.stack(labels_batch).to(device)\n",
    "\n",
    "        # Silently check for NaNs or Infs\n",
    "        has_nans = torch.isnan(images).any() or torch.isnan(labels).any()\n",
    "        has_infs = torch.isinf(images).any() or torch.isinf(labels).any()\n",
    "\n",
    "        # Silently verify label range\n",
    "        min_label, max_label = labels.min().item(), labels.max().item()\n",
    "        expected_min, expected_max = 0, 4\n",
    "        \n",
    "        # Display images with their corresponding raw redshift labels\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for j in range(num_samples):\n",
    "            label = labels[j].item()\n",
    "            # Normalize and prepare image for display\n",
    "            image_normalized = (images[j] + 1) / 2\n",
    "            image_normalized = image_normalized.mean(dim=0).cpu().numpy()\n",
    "            plt.subplot(1, num_samples, j + 1)\n",
    "            plt.imshow(image_normalized, cmap='gray')\n",
    "            plt.title(f\"Redshift: {label:.4f}\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if plot_histogram:\n",
    "            original_labels = []\n",
    "            # Collect labels with progress bar\n",
    "            for i in tqdm(range(len(dataset)), desc=\"Collecting labels for histogram\"):\n",
    "                current_label = dataset[i][1]\n",
    "                if isinstance(current_label, torch.Tensor):\n",
    "                    current_label = current_label.item()\n",
    "                original_labels.append(current_label)\n",
    "\n",
    "            if original_labels:\n",
    "                original_labels = np.array(original_labels)\n",
    "                # Plot histogram without additional prints\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.hist(original_labels, bins=100, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "                plt.title(\"Redshift Labels Distribution\")\n",
    "                plt.xlabel(\"Redshift Value\")\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.grid(axis='y', alpha=0.75)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "    except Exception as e_outer:\n",
    "        print(f\"Error during label inspection: {e_outer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac8fa3c-3696-4766-b458-4d6c55082a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: <class 'data_manage.HDF5ImageGenerator'>\n",
      "Dataset length: 204573\n",
      "Accessing indices: [0, 1, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect_labels(train_dataset, device, num_samples=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeda855-780b-4401-808f-907657b80875",
   "metadata": {},
   "source": [
    "## TensorBoard Setup\n",
    "\n",
    "Initializes TensorBoard for training visualization and monitoring.\n",
    "\n",
    "### Configuration\n",
    "- Log directory: ./tens_logs\n",
    "- Port: 6028 (adjustable)\n",
    "- External access enabled\n",
    "- Automatic startup with 5-second delay\n",
    "\n",
    "Access TensorBoard at:\n",
    "- Local: http://localhost:6028\n",
    "- Remote: http://altair:6028 (if using Altair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e93c0d-34db-4fa8-b7a6-ac15d1ea7ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.18.0 at http://altair:6028/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard is now running. You can access it at http://localhost:6028\n",
      "TensorBoard is now running. You can access it at http://altair:6028\n"
     ]
    }
   ],
   "source": [
    "#Initialize and start TensorBoard\n",
    "tensorboard_log_dir = \"./tens_logs\"\n",
    "writer = SummaryWriter(tensorboard_log_dir)\n",
    "\n",
    "tensorboard_port = 6028\n",
    "tensorboard_command = [\n",
    "    \"tensorboard\",\n",
    "    f\"--logdir={tensorboard_log_dir}\",\n",
    "    f\"--port={tensorboard_port}\",\n",
    "    \"--bind_all\"\n",
    "]\n",
    "try:\n",
    "    tensorboard_process = subprocess.Popen(tensorboard_command)\n",
    "    time.sleep(5)\n",
    "    print(f\"TensorBoard is now running. You can access it at http://localhost:{tensorboard_port}\")\n",
    "    print(f\"TensorBoard is now running. You can access it at http://altair:{tensorboard_port}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to start TensorBoard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09184116-77fd-49a5-af75-52711a67206c",
   "metadata": {},
   "source": [
    "## Checkpoint Cleanup\n",
    "\n",
    "This function manages disk space by removing older model checkpoints. By default, it keeps the 25 most recent checkpoints and deletes older ones.\n",
    "\n",
    "### Operation\n",
    "- Finds all checkpoint files (format: checkpoint_epoch_XXXX.pth)\n",
    "- Sorts them by epoch number\n",
    "- Keeps the most recent 25 checkpoints (adjustable)\n",
    "- Deletes all older checkpoints\n",
    "\n",
    "### Usage\n",
    "```python\n",
    "# Default: keep last 25 checkpoints\n",
    "cleanup_old_checkpoints(checkpoint_dir, current_epoch)\n",
    "\n",
    "# Custom Example: keep last 10 checkpoints\n",
    "cleanup_old_checkpoints(checkpoint_dir, current_epoch, keep_last_n=10)\n",
    "```\n",
    "\n",
    "This helps manage storage space during long training runs while ensuring recent progress isn't lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f2f635-46a8-4855-92bb-7f9eecacd14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_old_checkpoints(checkpoint_dir, current_epoch, keep_last_n=25):\n",
    "    \"\"\"\n",
    "    Cleans up old checkpoints, keeping only the most recent n checkpoints.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_dir (str): Directory containing checkpoints\n",
    "        current_epoch (int): Current training epoch\n",
    "        keep_last_n (int): Number of most recent checkpoints to keep\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    try:\n",
    "        # Get all checkpoint files\n",
    "        checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth'))\n",
    "        \n",
    "        # Extract epoch numbers and sort files by epoch\n",
    "        checkpoint_epochs = []\n",
    "        for f in checkpoint_files:\n",
    "            try:\n",
    "                epoch_num = int(f.split('epoch_')[-1].split('.')[0])\n",
    "                checkpoint_epochs.append((epoch_num, f))\n",
    "            except ValueError:\n",
    "                logger.warning(f\"Skipping file with invalid epoch format: {f}\")\n",
    "                continue\n",
    "        \n",
    "        checkpoint_epochs.sort(key=lambda x: x[0])  # Sort by epoch number\n",
    "        \n",
    "        # Keep the most recent n checkpoints\n",
    "        files_to_delete = checkpoint_epochs[:-keep_last_n] if len(checkpoint_epochs) > keep_last_n else []\n",
    "        \n",
    "        # Delete old checkpoints\n",
    "        for _, filepath in files_to_delete:\n",
    "            try:\n",
    "                os.remove(filepath)\n",
    "                logger.info(f\"Deleted old checkpoint: {filepath}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error deleting checkpoint {filepath}: {str(e)}\")\n",
    "                \n",
    "        if files_to_delete:\n",
    "            logger.info(f\"Cleaned up {len(files_to_delete)} old checkpoints\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during checkpoint cleanup: {str(e)}\")\n",
    "        logger.exception(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7ab3e-9a5c-4015-a0a4-8f758aea202e",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "This is the main training function for our diffusion model. Here's what happens during training:\n",
    "\n",
    "### Setup Phase\n",
    "- Initializes UNet model with 5 input/output channels\n",
    "- Sets up AdamW optimizer and learning rate scheduler\n",
    "- Configures EMA (Exponential Moving Average) for stable training\n",
    "- Resumes from checkpoint if specified (args.resume = True)\n",
    "\n",
    "### Per Epoch\n",
    "1. **Training**:\n",
    "   - Processes each batch of images with their redshift labels\n",
    "   - Adds small noise to labels (0.01 std) for robustness\n",
    "   - Trains diffusion model to predict noise\n",
    "   - Updates EMA model after each step\n",
    "   - Tracks loss using Huber/Smooth L1\n",
    "\n",
    "2. **Visualization** (every 2 epochs):\n",
    "   - Generates 16 new images across redshift range [0,4]\n",
    "   - Shows comparison with real images\n",
    "   - Saves results to TensorBoard\n",
    "\n",
    "3. **Checkpointing**:\n",
    "   - Saves model state every 2 epochs\n",
    "   - Keeps best model based on validation loss\n",
    "   - Cleans up old checkpoints every 50 epochs (keeps last 25)\n",
    "\n",
    "4. **Validation**:\n",
    "   - Evaluates model on validation set\n",
    "   - Updates learning rate based on validation loss\n",
    "   - Saves new best model if validation improves\n",
    "\n",
    "### Monitoring\n",
    "All progress is tracked in:\n",
    "- Console output with progress bars\n",
    "- TensorBoard logs (losses, images, learning rate)\n",
    "- Detailed log files\n",
    "\n",
    "The training can be resumed at any point using saved checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "120f7a29-1d1e-42b0-a144-c3757d7aa8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, lr, ema_decay, train_loader, val_loader, writer):\n",
    "    \"\"\"\n",
    "    Main training function for the diffusion model.\n",
    "    \n",
    "    Args:\n",
    "        args: Configuration arguments (epochs, batch_size, etc.)\n",
    "        lr: Learning rate\n",
    "        ema_decay: Exponential Moving Average decay rate\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        writer: TensorBoard writer for logging\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================\n",
    "    # Logger Setup\n",
    "    # =========================\n",
    "    # Get the logger for this module\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Set up handlers if they don't exist\n",
    "    if not logger.handlers:\n",
    "        # Console output handler\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        ch.setFormatter(formatter)\n",
    "        logger.addHandler(ch)\n",
    "        \n",
    "        # File output handler - saves to training.log\n",
    "        fh = logging.FileHandler('training.log')\n",
    "        fh.setLevel(logging.INFO)\n",
    "        fh.setFormatter(formatter)\n",
    "        logger.addHandler(fh)\n",
    "    \n",
    "    # Filter out repetitive messages from console output\n",
    "    class MessageFilter(logging.Filter):\n",
    "        def filter(self, record):\n",
    "            excluded_messages = [\n",
    "                \"Successfully logged images to TensorBoard\",\n",
    "                \"Successfully logged real images to TensorBoard\",\n",
    "                \"Generating and logging images for epoch\",\n",
    "                \"Generated images range:\",\n",
    "                \"Starting training, logs will be written to\",   \n",
    "            ]\n",
    "            return not any(msg in record.msg for msg in excluded_messages)\n",
    "    \n",
    "    # Apply filter only to console output\n",
    "    for handler in logger.handlers:\n",
    "        if isinstance(handler, logging.StreamHandler):\n",
    "            handler.addFilter(MessageFilter())\n",
    "    \n",
    "    # =========================\n",
    "    # Model Setup\n",
    "    # =========================\n",
    "    # Setup device and directories\n",
    "    device = torch.device(args.device)\n",
    "    checkpoint_dir = './Model_Checkpoints'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    logger.info(f\"Starting training, logs will be written to: {writer.log_dir}\")\n",
    "    \n",
    "    # Initialize UNet model with 5 input/output channels (g,r,i,z,y bands)\n",
    "    model = UNet_conditional_conv(c_in=5, c_out=5, y_dim=1).to(device)\n",
    "    # AdamW optimizer with specified learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    # Reduce learning rate when validation loss plateaus\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=False)\n",
    "    \n",
    "    # Initialize Exponential Moving Average of model weights\n",
    "    ema = EMA(model, beta=ema_decay)\n",
    "    ema_model = ema.get_ema_model()\n",
    "    \n",
    "    # Initialize diffusion process\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
    "    \n",
    "    # =========================\n",
    "    # Checkpoint Loading\n",
    "    # =========================\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    \n",
    "    start_epoch = 0\n",
    "    if args.resume:\n",
    "        # Load previous training state if resuming\n",
    "        start_epoch = load_checkpoint(\n",
    "            model, ema, optimizer, checkpoint_dir, args, diffusion, device, args.start_epoch\n",
    "        )\n",
    "        # Try to load previous best validation loss\n",
    "        try:\n",
    "            best_model_checkpoint = torch.load(best_model_path, map_location=device)\n",
    "            best_val_loss = best_model_checkpoint.get('val_loss', float('inf'))\n",
    "            logger.info(f\"Loaded previous best validation loss: {best_val_loss:.4f}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not load previous best validation loss: {e}, starting from infinity\")\n",
    "    \n",
    "    # =========================\n",
    "    # Training Loop Setup\n",
    "    # =========================\n",
    "    total_epochs = args.epochs\n",
    "    cumulative_loss = 0.0\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    logger.info(f\"Training started, total epochs: {total_epochs}\")\n",
    "    writer.add_text('Run Info', f\"Starting training for {total_epochs} epochs.\", 0)\n",
    "    writer.flush()\n",
    "    \n",
    "    generated_images = None\n",
    "    \n",
    "    # =========================\n",
    "    # Main Training Loop\n",
    "    # =========================\n",
    "    for epoch in range(start_epoch, total_epochs):\n",
    "        # Clear console output periodically for cleanliness\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "        epoch_start_time = time.time()\n",
    "        model.train()  # Set model to training mode\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # Process each batch with progress bar\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{total_epochs}\") as pbar:\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                # Move data to correct device\n",
    "                images = images.to(device)\n",
    "                labels = labels.float().to(device)\n",
    "                \n",
    "                # Ensure labels have correct shape\n",
    "                if labels.dim() == 0:\n",
    "                    labels = labels.unsqueeze(0).unsqueeze(1)\n",
    "                elif labels.dim() == 1:\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                \n",
    "                # Add small noise to labels for robustness\n",
    "                labels += torch.randn_like(labels) * 0.01\n",
    "                labels = torch.clamp(labels, 0, 4)\n",
    "                \n",
    "                # Get random timesteps and add noise to images\n",
    "                t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "                x_t, noise = diffusion.noise_images(images, t)\n",
    "                \n",
    "                # Predict noise and calculate loss\n",
    "                predicted_noise = model(x_t, t, labels)\n",
    "                loss = nn.functional.smooth_l1_loss(noise, predicted_noise)\n",
    "                \n",
    "                # Optimization step\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update EMA model\n",
    "                ema.step_ema(ema_model, model)\n",
    "    \n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix(HuberLoss=loss.item())\n",
    "                \n",
    "                # Periodic TensorBoard updates\n",
    "                if i % 10 == 0:\n",
    "                    writer.flush()\n",
    "    \n",
    "        # =========================\n",
    "        # End of Epoch Processing\n",
    "        # =========================\n",
    "        # Calculate average loss for epoch\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        cumulative_loss += avg_epoch_loss\n",
    "        \n",
    "        # Log training metrics\n",
    "        writer.add_scalar('Loss/train_epoch', avg_epoch_loss, epoch)\n",
    "        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)\n",
    "        writer.flush()\n",
    "    \n",
    "        # =========================\n",
    "        # Image Generation & Logging\n",
    "        # =========================\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            logger.info(f\"Generating and logging images for epoch {epoch + 1}\")\n",
    "            \n",
    "            # Generate new images\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    # Generate 16 images across redshift range 0-4\n",
    "                    sample_labels = torch.linspace(0, 4, 16).to(device).unsqueeze(1)\n",
    "                    generated_images = diffusion.sample(ema_model, 16, sample_labels)\n",
    "                    generated_images = denormalize_images(generated_images)\n",
    "                    \n",
    "                    # Prepare images for visualization\n",
    "                    generated_images_rgb = generated_images[:, :3]\n",
    "                    generated_images_rgb = (generated_images_rgb - generated_images_rgb.min()) / (generated_images_rgb.max() - generated_images_rgb.min() + 1e-5)\n",
    "                    \n",
    "                    logger.info(f\"Generated images range: [{generated_images_rgb.min():.3f}, {generated_images_rgb.max():.3f}]\")\n",
    "                    \n",
    "                    # Log to TensorBoard\n",
    "                    grid = make_grid(generated_images_rgb, nrow=4)\n",
    "                    writer.add_image(f'Generated_Images/epoch_{epoch + 1}', grid, epoch)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during image generation: {str(e)}\")\n",
    "                logger.exception(e)\n",
    "            \n",
    "            # Log real images for comparison\n",
    "            try:\n",
    "                if val_loader is not None:\n",
    "                    real_images, _ = get_random_val_batch(val_loader)\n",
    "                    if real_images is not None:\n",
    "                        real_images = real_images.to(device)[:16]\n",
    "                        real_images_rgb = real_images[:, :3]\n",
    "                        real_images_rgb = (real_images_rgb - real_images_rgb.min()) / (real_images_rgb.max() - real_images_rgb.min() + 1e-5)\n",
    "                        grid_real = make_grid(real_images_rgb, nrow=4)\n",
    "            \n",
    "                        writer.add_image(f'Real_Images/epoch_{epoch + 1}', grid_real, epoch)\n",
    "                        logger.info(\"Successfully logged real images to TensorBoard\")\n",
    "                    else:\n",
    "                        logger.warning(\"No real images obtained for logging.\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during real image logging: {str(e)}\")\n",
    "                logger.exception(e)\n",
    "            \n",
    "            writer.flush()\n",
    "            logger.info(\"Successfully logged images to TensorBoard\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            save_checkpoint(\n",
    "                model=model,\n",
    "                ema=ema,\n",
    "                optimizer=optimizer,\n",
    "                epoch=epoch,\n",
    "                checkpoint_dir=checkpoint_dir,\n",
    "                args=args,\n",
    "                average_loss=avg_epoch_loss,\n",
    "                diffusion=diffusion,\n",
    "                best_val_loss=best_val_loss   \n",
    "            )\n",
    "            \n",
    "            # Periodic cleanup of old checkpoints\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                logger.info(f\"Performing checkpoint cleanup at epoch {epoch + 1}\")\n",
    "                cleanup_old_checkpoints(checkpoint_dir, epoch, keep_last_n=25)\n",
    "    \n",
    "        # =========================\n",
    "        # Validation\n",
    "        # =========================\n",
    "        if val_loader is not None:\n",
    "            val_loss = validate(model, val_loader, diffusion, device, torch.nn.functional.smooth_l1_loss)\n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # Log validation metrics\n",
    "            writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "            writer.add_scalar('Best_Val_Loss', best_val_loss, epoch)\n",
    "            \n",
    "            # Save best model if validation improves\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                save_best_model(\n",
    "                    model=model,\n",
    "                    ema=ema,\n",
    "                    optimizer=optimizer,\n",
    "                    epoch=epoch,\n",
    "                    val_loss=val_loss,\n",
    "                    best_model_path=best_model_path,\n",
    "                    args=args,\n",
    "                    average_loss=avg_epoch_loss,\n",
    "                    diffusion=diffusion\n",
    "                )\n",
    "                logger.info(f\"New best model saved with validation loss {best_val_loss:.4f}\")\n",
    "            else:\n",
    "                logger.debug(f\"Validation loss {val_loss:.4f} did not improve best {best_val_loss:.4f}\")\n",
    "    \n",
    "        writer.flush()\n",
    "    \n",
    "        # Log epoch timing\n",
    "        epoch_end_time = time.time()\n",
    "        logger.debug(\n",
    "            f\"Epoch {epoch + 1}/{total_epochs} finished with average loss: {avg_epoch_loss:.4f} \"\n",
    "            f\"in {epoch_end_time - epoch_start_time:.2f} seconds\"\n",
    "        )\n",
    "    \n",
    "    # =========================\n",
    "    # Final Cleanup and Logging\n",
    "    # =========================\n",
    "    total_training_time = time.time() - total_start_time\n",
    "    final_avg_loss = cumulative_loss / total_epochs\n",
    "    \n",
    "    # Log final metrics\n",
    "    writer.add_scalar('Loss/final_average', final_avg_loss, total_epochs)\n",
    "    writer.add_text('Training Time', f'Total training time: {total_training_time:.2f} seconds')\n",
    "    writer.flush()\n",
    "    \n",
    "    logger.info(\n",
    "        f\"Training completed in {total_training_time:.2f} seconds with \"\n",
    "        f\"average loss: {final_avg_loss:.4f}\"\n",
    "    )\n",
    "    \n",
    "    return final_avg_loss, generated_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be728215-c5c2-4638-b5c6-d826af321a9a",
   "metadata": {},
   "source": [
    "## Start Training\n",
    "\n",
    "This cell starts the training process by calling our training function with the configured parameters.\n",
    "\n",
    "### Parameters Used:\n",
    "- Arguments from args class (epochs, batch_size, etc.)\n",
    "- Learning rate: 5e-5 (from args.lr)\n",
    "- EMA decay: 0.995 (for model averaging stability)\n",
    "- Training data loader\n",
    "- Validation data loader\n",
    "- TensorBoard writer for logging\n",
    "\n",
    "### Returns:\n",
    "- average_loss: Final training loss\n",
    "- generated_images: Last batch of generated galaxies\n",
    "\n",
    "Monitor progress in:\n",
    "- Terminal output\n",
    "- TensorBoard (http://localhost:6028)\n",
    "- Log files in './Logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36516e-b50e-4a47-8844-357a3404db21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 245/600: 100%|██████████| 1599/1599 [04:04<00:00,  6.54it/s, HuberLoss=0.0246]\n",
      "Epoch 246/600: 100%|██████████| 1599/1599 [04:05<00:00,  6.52it/s, HuberLoss=0.0358]\n",
      "999it [00:10, 96.77it/s]\n",
      "Epoch 247/600: 100%|██████████| 1599/1599 [04:04<00:00,  6.55it/s, HuberLoss=0.0311]\n",
      "Epoch 248/600:  55%|█████▍    | 878/1599 [02:13<01:51,  6.49it/s, HuberLoss=0.0164]"
     ]
    }
   ],
   "source": [
    "# Call train function and pass the witer\n",
    "average_loss, generated_images = train(\n",
    "    args,\n",
    "    lr=args.lr,\n",
    "    ema_decay=0.995,\n",
    "    train_loader=train_loader,  # Ensure train_dataloader is defined\n",
    "    val_loader=val_loader,      # Ensure val_dataloader is defined\n",
    "    writer=writer                   # Pass the SummaryWriter instance\n",
    ")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa62678-852f-4b71-9f51-7303f593df06",
   "metadata": {},
   "source": [
    "## TensorBoard Cleanup\n",
    "\n",
    "This cell defines and registers an automatic cleanup function for TensorBoard.\n",
    "\n",
    "### When Cleanup Occurs:\n",
    "The TensorBoard process will terminate when:\n",
    "- You shutdown the Jupyter kernel\n",
    "- You close and disconnect from the server\n",
    "- You restart the kernel\n",
    "\n",
    "It will NOT terminate when:\n",
    "- You finish running all cells\n",
    "- You close just the browser tab\n",
    "- You're idle in the notebook\n",
    "\n",
    "For clean shutdown, either:\n",
    "- Use Kernel -> Shutdown in Jupyter\n",
    "- Properly disconnect from server\n",
    "- Use Kernel -> Restart\n",
    "\n",
    "Otherwise, TensorBoard will continue running in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "594d9638-9b0e-4785-bdfb-bed498855575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.shutdown_tensorboard()>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shutdown_tensorboard():\n",
    "    tensorboard_process.terminate()\n",
    "    tensorboard_process.wait()\n",
    "    logger.info(\"TensorBoard has been terminated.\")\n",
    "\n",
    "atexit.register(shutdown_tensorboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3bc5f-f063-47a5-afc3-c6961bb55256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
